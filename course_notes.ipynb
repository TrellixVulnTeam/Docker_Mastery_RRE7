{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is docker? The three innovations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD / SHIP / RUN\n",
    "The **BUILD/SHIP/RUN** cycle consists of three steps to take previously non containarized software, turn it into a docker image, put it on a registry and deploy it on containers.\n",
    "\n",
    "Most projects that gradudated from [the cloud native foundation](https://cncf.io) make the assumption that you're using a container workflow of build/ship/run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The three innovations\n",
    "1. The docker **IMAGE**\n",
    "2. The docker **REGISTRY**\n",
    "3. The docker **CONTAINER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The docker registry \n",
    "\n",
    "* Known as the OCI registry spec, a standard for distributing the images.\n",
    "* Docker Hub is the default, github and gitlab have their own.\n",
    "* A built image has a unique SHA hash that will allow or verification between two systems/hosts that the image contains the same files/metadata...\n",
    "* Usualy done via the command docker push or docker pull\n",
    "* **This is one of the core values of docker. We can take software that made on one machine with all its dependencies and run it on another machine, seamlessly and regardless if the two machines are running on different distributions of an OS (will run the same on Ubuntu or CentOs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The docker container \n",
    "\n",
    "* Running an image after downloading it into a server.\n",
    "* A container is known as a **namespace**. This is what makes sure that the app running inside the containers can't see the rest of the operating system.\n",
    "    * A namespace is basicly a blanch file system with only the files from the image that was built.\n",
    "    * It would have it's own IP address, NIC (Network Interface Controller) and process list.\n",
    "* Reruning the docker run command on that image would spin up a new instance of this image that is isolated from the first.\n",
    "    * If the docker run command if run on another server with a docker engine then it yields a high availability setup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Container Run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [Play With Docker Website](https://labs.play-with-docker.com/) we can run a few demo commands before doing any local installs of Docker\n",
    "\n",
    "* You will need an account with [Docker](https://hub.docker.com/), it's free\n",
    "* Once logged in to [Play With Docker Website](https://labs.play-with-docker.com/) you will see a green start button and once clicked a timer will be show for the time remaining in the session.\n",
    "* You will be able to deploy docker images on infrastructure provided by Docker.\n",
    "* Steps for demo:\n",
    "    * click on 'add new instances'\n",
    "    * run \"docker version\" :\n",
    "        * Gets details about the client and the engine currently running\n",
    "    * connecting to from client to server can happen over many ways:\n",
    "        * Socket\n",
    "        * TCP/TLS\n",
    "        * SSH tunnel\n",
    "    * run \"docker run -d -p 8800:80 httpd\"\n",
    "        * -d -> detach, runs in background\n",
    "        * -p -> port, which ports are opened and published on host IP so that it can be accessed remotely\n",
    "            * first number is the port on the host on which we're listening\n",
    "            * second number is the container port on which we're connecting\n",
    "        * httpd -> apache server image\n",
    "        * ouput will resemble the below:\n",
    "            * Unable to find image 'httpd:latest' locally\n",
    "            * latest: Pulling from library/httpd\n",
    "            * 1efc276f4ff9: Pull complete \n",
    "            * aed046121ed8: Pull complete \n",
    "            * 4340e7be3d7f: Pull complete \n",
    "            * 80e368ef21fc: Pull complete \n",
    "            * 80cb79a80bbe: Pull complete \n",
    "            * Digest: sha256:343452ec820a5d59eb3ab9aaa6201d193f91c3354f8c4f29705796d9353d4cc6\n",
    "            * Status: Downloaded newer image for httpd:latest\n",
    "            * bbaf9c895f19f301e40c7d2bd743127e372f8932b997ca238b5eaaeb13f6ec88\n",
    "        * The output can be interpreted as such:\n",
    "            * the various **layers** of the image are downloaded/pull\n",
    "            * then it will create the networking, virtual interface, file system, load the file from the image into the file system\n",
    "            * then it will startup the httpd process in its own namespace.  \n",
    "    * run a curl command on the local host (machine from which this container is being instanciated) to verify that it's up: curl localhost:8800\n",
    "        * output is: ```<html><body><h1>It works!</h1></body></html >```\n",
    "    * run \"docker ps\" to view running containers:\n",
    "        * | CONTAINER ID | IMAGE | COMMAND            | CREATED        | STATUS        | PORTS                | NAMES             |\n",
    "          |--------------|-------|--------------------|----------------|---------------|----------------------|-------------------|\n",
    "          | bbaf9c895f19 | httpd | \"httpd-foreground\" | 12 minutes ago | Up 12 minutes | 0.0.0.0:8800->80/tcp | confident_johnson |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Docker? Why Now?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker's \"raison d'etre\" come from frictions that were being faced relating to speed a efficiency of packaging and deploying software.\n",
    "\n",
    "The three main reason are:\n",
    "* Isolation:\n",
    "    * During the move from mainframe to servers (early 2000s), it was very rare that an app would fully utilise the capacity of the servers on which they would run. You ended up with mutliple apps colocating on the same servers, this increased complexity in managing them and made them prone to outages (e.g: one change for an app would cause an effect on other apps).\n",
    "    * This lead to the emergence of VMs (Virtual Machines), fewer apps on multiple VMs all riding on the same hosts. This would lead to an exploding number of VMs which were each spun up with their own OS. Isolation was sort of solved but complexity outweighed the benefits.\n",
    "    * Then Docker comes along and removes the need for all the different operating systems on each VM. Each application has its own namespace that is isolated and managing them comes easily through the docker/kubernetes cli. You can now run multiple version of the same app on the same host without any conflict.\n",
    "* Environment\n",
    "    * With VMs also came the deployement of a large number of types of environments. The running joke being \"Works on my machine\".\n",
    "    * The container image has become a sort of contract between what the app runs and where its running. Just like actual shipping containers where those who ship something don't care what the ship that was carrying the container looked like and the people transporting the container didn't care what was inside it.\n",
    "        * This is done through a consistent standard (the OCI format) which has two specs, an image and a runtime spec.\n",
    "        * this ensures that the container will always be run with the same consistent way and same dependencies it was built with.\n",
    "* Speed\n",
    "    * Not the speed of CPU and processors but the speed of business, the ability to test and execute on ideas in a timely manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Course Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Course Ressources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github repo\n",
    "https://github.com/bretfisher/udemy-docker-mastery\n",
    "\n",
    "### Docker commands, cheatsheets & slides\n",
    "Downloaded in the \"course_ressources folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: The best way to setup Docker for your OS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Docker\n",
    "\n",
    "Get the [Docker Desktop](https://www.docker.com/products/docker-desktop/) and install it on your machine.\n",
    "\n",
    "There are 3 major ways to run containers:\n",
    "* Locally (Docker Desktop, Remote Desktop)\n",
    "* Servers (Docker Engine, K8s)\n",
    "* PaaS (Cloud Run, Fargate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Creating and usig containers like a boss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.Check the Docker Install and Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the current version of Docker\n",
    "Returns the version of the **client** as well the server, a.k.a **the engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get additional information on Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the full list of commands in Docker\n",
    "\n",
    "This is not a full list of the commands. You will notice below the sub modules that are accessible via docker manage  \n",
    "commands, under **Management Commands:**\n",
    "  \n",
    "Management Commands:\n",
    "* builder     Manage builds\n",
    "* buildx*     Docker Buildx (Docker Inc., v0.8.2)\n",
    ".  \n",
    ".  \n",
    ".  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.Starting a Nginx web server\n",
    "\n",
    "In this section we will:\n",
    "* contract images to containers\n",
    "* run/stop/remote containers\n",
    "* check container logs and process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images vs. Containers\n",
    "\n",
    "**Images** are the binaries/libraries/source code that will make up our application. A **container** is a running   \n",
    "instance of that image. You can have mutliple containers running from the same image. \n",
    "\n",
    "Images are obtained from registries, [**Docker Hub**](https://hub.docker.com/) being the default registry.   \n",
    "(sort of what github is to source code, registries are to images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# command to get the image from the registry and running it\n",
    "docker container run --publish 80:80 nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the background docker looked for the latest version of nginx in Docker Hub,  \n",
    "pulled it into our machine and started it  \n",
    "as a process. The --publish argument exposes my local port 80 and sends all  \n",
    "traffic comming to it to the container's  \n",
    "port 80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't want the process to run in the foreground we can add the --detach  \n",
    "argument and have all the above be done in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container run --publish 80:80 --detach nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the container was started in the background we got in the output the unique container ID which  \n",
    "we can use to compare with the output of the ```docker ps``` or ```docker container ls``` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# we can check that the container is actually up and running\n",
    "docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the running container you can use ```docker container stop ${CONTAINER_ID}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container stop 188eb98e7d4e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And verify that the container is no longer running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If i want to see all the containers, even those that are not running then i use   \n",
    " ```docker container ls -a```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ls -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can always give names to our containers otherwise they will be given randomly generated  \n",
    "names using this syntax `<adjective>_<name_of_famous_scientist>`.   \n",
    "\n",
    "If we want to specify the name we use the argument `--name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container run --publish 80:80 --detach --name webhost nginx\n",
    "docker container ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to view the container logs we use `docker container logs ${CONTAINER_NAME}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container logs webhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the processes in the container use `docker container top ${CONTAINER_NAME}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container top webhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#you can see that the new container had a custom name\n",
    "docker container stop d4ae91d827ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup the containers by listing all containers and removing them using  \n",
    "`docker container rm [${CONTAINER_ID}  ${CONTAINER_ID} ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container rm d4a 188\n",
    "docker container ls -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.Debrief, what happens when we run a container\n",
    "\n",
    "1. Looks for images in local cache\n",
    "2. Look for images in registry if not found locally\n",
    "3. Download the latest version\n",
    "4. Create and new container based on the image and prepare it for start-up\n",
    "5. Give the container a virtual IP on private network within the docker engine\n",
    "6. Open up a port on the host and forward it to the port in the container\n",
    "7. Start container based on CMD found in the image's Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.Containers vs Virtual Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containers aren't mini VMs\n",
    "\n",
    "* They are just processes\n",
    "* They are limited to what ressources they can access\n",
    "* They exit when process stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.Window Containers: Should you consider them?\n",
    "\n",
    "Containers are restricted processes that are running on the host's OS kernel.  \n",
    "For example a Python image built for linux/x84_64 won't run as a python.exe on   \n",
    "a Windows kernel. Which is why Docker utilizes a lightwheight Linux VM to run  \n",
    "the containers.\n",
    "\n",
    "From Docker's inception in 2013 to 2016, we could build images for multiple  \n",
    "architectures (amd64, arm/v6, arm/v7, i386, etc.) but not for the Windows   \n",
    "kernel itself. Docker was Linux-only.\n",
    "\n",
    "In 2016 we got \"Windows Containers\" support from Microsoft. When you think of   \n",
    "images, realize they are always kernel (Linux/Windows) and architecture   \n",
    "(arm64, amd64, etc.) specific. Docker does this seamlessly in the background  \n",
    "with a \"manifest\". It downloads the best image for the platform your Docker  \n",
    "Engine is running on.\n",
    "\n",
    "You can enable Windows Container mode in Docker Desktop for Windows by clicking  \n",
    "\"Switch to Windows containers\" in the Docker whale menu, which then switches  \n",
    "from WSL2 to Hyper-V running a slim Windows VM. It's an either-or setting,  \n",
    "you'll have to decide which OS you want to run your containers on and stick to it.  \n",
    "\n",
    "Sadly, the truth is that Windows Containers never caught on in a major way.  \n",
    "Microsoft even built a Windows-based MSSQL image, but has since discontinued   \n",
    "it in 2021 in favor of their Linux-based MSSQL image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.Arm Support for MySQL\n",
    "\n",
    "The official MySQL image only supports Intel/AMD processors. MariaDB is an  \n",
    "alternative if you're using Apple M1 or Raspberry Pi (both based on arm64 processors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23-24.Assignement: Manage multiple containers\n",
    "\n",
    "[Docker Official Documentation](https://docs.docker.com) is your friend as well  as the --help argument at the end of each command.\n",
    "\n",
    "### Assignement Instructions\n",
    "* Run an `nginx`, `mysql` and `httpd` (apache) server\n",
    "* Run all of the in `--detach` mode (-d), name them with --name\n",
    "* Specify the ports, nginx should listen to 80:80, httpd to 8080:80 and mysql to 3306:3306\n",
    "* When running mysql, use the `--env` option (-e) to pass in `MYSQL_RANDOM_ROOT_PASSWORD=yes`\n",
    "* Use the `docker container logs` on mysql to find the random password on startup\n",
    "* Clean it all up afterwards using the `docker container stop` and `docker container rm`\n",
    "* Verify that everything got shutdown correctly using the `docker container ls`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# run instances\n",
    "docker container run --detach -p 80:80 --name nginx nginx\n",
    "docker container run --detach -p 8080:80 --name httpd httpd\n",
    "docker container run --detach -p 3306:3306 -e MYSQL_RANDOM_ROOT_PASSWORD='yes' --name mysql mysql \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "#verify instances\n",
    "docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# find generated password\n",
    "docker container logs mysql | grep \"GENERATED ROOT PASSWORD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# cleanup\n",
    "docker container stop nginx\n",
    "docker container stop httpd\n",
    "docker container stop mysql\n",
    "docker container rm nginx\n",
    "docker container rm httpd\n",
    "docker container rm mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25.What's going on in containers: CLI process monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful commands to view container processes\n",
    "\n",
    "1. docker cotainer top - process list in one container\n",
    "2. docker container inspect - detials of one container config\n",
    "3. docker container stats - performance stats for all containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# run instances\n",
    "docker container run --detach -p 80:80 --name nginx nginx\n",
    "docker container run --detach -p 3306:3306 -e MYSQL_RANDOM_ROOT_PASSWORD='yes' --name mysql mysql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container top nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container inspect mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# cleanup\n",
    "docker container stop nginx\n",
    "docker container stop mysql\n",
    "docker container rm nginx\n",
    "docker container rm mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26-27. Getting a shell inside the container\n",
    "\n",
    "### Useful commands\n",
    "\n",
    "1. docker container run -it - start a new container interactively\n",
    "2. docker container exec -it - run additional commands in existing container\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### docker run -it\n",
    "-i : interactive  \n",
    "-t : allocate a pseudo TTY (a prompt similar to ssh)  \n",
    "bash : an optional argument that can be passed to the container on startup  \n",
    "here it makes the container start with a bash terminal  \n",
    "\n",
    "\n",
    "docker container run -it --name nginx nginx bash\n",
    "\n",
    "#### Command \n",
    "docker container run -it --name nginx nginx bash\n",
    "\n",
    "Notice that when exiting the shell the container gets stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### docker run -it\n",
    "\n",
    "If I want to see a shell inside an already running container\n",
    "\n",
    "#### Command:\n",
    "docker container exec -it nginx bash\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28-29 Docker networks: concepts for private and public comms in containers\n",
    "\n",
    "When starting a container you're connecting, in the background, to a particular  \n",
    "docker network (the default being the bridge network).\n",
    "\n",
    "\n",
    "Each virtual network routes through a NAT firewall on host IP. The Docker deamon  \n",
    "configuring the host IP on it default interface so that your containers can   \n",
    "interact with the internet.\n",
    "\n",
    "[NAT Firewal Definition](https://nordvpn.com/blog/what-is-nat-firewall/)\n",
    "```  \n",
    "A Network Address Translation (NAT) firewall operates on a router to protect  \n",
    "private networks. It works by only allowing internet traffic to pass through if  \n",
    "a device on the private network requested it. A NAT firewall protects the   \n",
    "identity of a network and doesn't show internal IP addresses to the internet.\n",
    "```  \n",
    "\n",
    "All containers within a network can talk to each other inside the host  \n",
    "without the -p (port). For example a mysql and a php/apache container can  \n",
    "communicate on the same network named \"my_web_app\" without exposing their ports  \n",
    "to the rest of the physical network.\n",
    "\n",
    "This brings us to the concept of `\"Batteries included, but removable\"` which  \n",
    "means that the defaults work well in most cases but are easily customizable  \n",
    "(creating mutliple network, one per app, or different networks depending on  \n",
    "security requirements)\n",
    "\n",
    "You can attach container to more than one virtual network (or none).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container run -d  -p 80:80 --name nginx nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Here we see that the host port 80 is exposed to the container's port 80 \n",
    "#through a tcp connexion\n",
    "docker container port nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#We may assume that the container uses the same IP as the host but by default \n",
    "#that is not true. We'll use the format comand instead of grep to filter\n",
    "#to the correct node in the json output off the docker inspect command\n",
    "docker container inspect --format \"{{.NetworkSettings.IPAddress}}\" nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker container stop nginx\n",
    "docker container rm nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#check the host's IP address, it does't have to match that of the host\n",
    "ifconfig en0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30.Docker Netwoks: CLI Management of Virtual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful commands\n",
    "\n",
    "* Show networks `docker network ls`\n",
    "* Inspect a network `docker network inspect`\n",
    "* Create a network `docker network create --driver`\n",
    "    * It has the optional `--driver` argument that we can use to specify built-in  \n",
    "    or third-party driver to create virtual networks\n",
    "* Attach/detach a network to a conttainer `docker netwrok connect/disconnect`\n",
    "    * Used t connect/disconnect a live running container so that a NIC is   \n",
    "    created/destroyed on a virtual network for that container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker network ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge Network \n",
    "\n",
    "The bridge network is the default network that bridges throught the [NAT firewall](https://www.comparitech.com/blog/vpn-privacy/nat-firewall/)  \n",
    "to the physical network that your host is connected to.\n",
    "\n",
    "* (Note) A NAT firewall works by only allowing internet traffic to pass through the gateway if a device on the private network requested it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker network inspect bridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## to find a specific item in the docker netork inspect\n",
    "docker network inspect bridge --format {{.IPAM.Config}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The host network\n",
    "\n",
    "A special kind of network that skips the virtual network of Docker and attaches  \n",
    "the container directly to the host interface. Its a boost for performance but  \n",
    "sacrifices in security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker network inspect host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new network\n",
    "\n",
    "Notice how the default for `DRIVER` for the new network was `bridge`. It's a  \n",
    "built-in driver that create a virtual network locally with its own subnet. It  \n",
    "lacks some of the more advanced features, such as private networking between hosts  \n",
    "like other 3rd party driver like `Weave`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker network create my_app_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker network ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#check out all the arguments that you can specify during the creatiion of networks\n",
    "docker network create --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a network to a container on startup\n",
    "\n",
    "Using the `--network` option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container run -d -p 80:80 --name nginx --network my_app_net nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#You will see the new container running on this network\n",
    "docker network inspect my_app_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting running containers to existing networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker network --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker network ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## connect the nginx container (aready connected to the my_app_net) to the default  \n",
    "## bridge network\n",
    "docker network connect bridge nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "##inspecting the nginx container, you'll now see that its on two networks\n",
    "docker container inspect --format {{.NetworkSettings.Networks}} nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## to reverse out the above\n",
    "docker network disconnect bridge nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "##inspecting the nginx container, you'll now see only one left\n",
    "docker container inspect --format {{.NetworkSettings.Networks}} nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container stop nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container rm nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31.Docker Networks: DNS & how containers find each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key concepts\n",
    "\n",
    "* Undertand how DNS is the key to inter-container comms\n",
    "    * You can't fully rely on IP adresses and need DNS because things are  \n",
    "    dynamic (i.e: if you stop a few containers but restart them in a different  \n",
    "    order, they may not have the same IP address)\n",
    "    * Docker uses the container names as the equivalent of host names when   \n",
    "    containers are talking to each other.\n",
    "* Understand how custom & default networks differ in how they deal with DNS\n",
    "* Learn how to use `--link` in the `container run` command to enable DNS on the   \n",
    "default bridge network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container run -d -p 80:80 --name nginx --network my_app_net nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic DNS resolution\n",
    "\n",
    "On the new netwrok **my_app_net** you get a special feature because its not the   \n",
    "default bridge network and that is `automatic DNS resolution` for all containers  \n",
    "on that network using their name. When a new container is created on that network  \n",
    "it will be able to communicate with other containers, on that network, regardless  \n",
    "of what the IP address is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container run -d --name nginx_2 --network my_app_net nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker network inspect my_app_net --format {{.Containers}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# you can see from output that the two containers are able to communicate using  \n",
    "# only the container names\n",
    "docker container exec  -i nginx_2 ping nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcommings of the default bridge network\n",
    "\n",
    "The bridge network does not have any built-in DNS resolution. You can use `--link`  \n",
    "to create manual links between the containers as a workaround. However its much  \n",
    "easier to create a new network so as not to have to create these links every time.  \n",
    "Later when using `Docker Compose` it gets even easier as it will create these  \n",
    "virtual networks when you start up an entire app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32-33.Assignment: Using Containers for CLI Testing\n",
    "\n",
    "Scenario: You need to check the different versions of curl installed on two different  \n",
    "linux distros. In the VM era you'd have to wait for the OS to install and the VMs to  \n",
    "startup. Now all you have to do is spin up two containers and run your commands  \n",
    "from them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a Centos container\n",
    "\n",
    "    docker run --rm -it centos:7 bash\n",
    "\n",
    "**from within the container's shell**\n",
    "\n",
    "    yum update curl    \n",
    "    curl --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a ubuntu container\n",
    "\n",
    "    docker run --rm -it ubuntu:14.04 bash\n",
    "\n",
    "**from within the container's shell**\n",
    "\n",
    "    apt-get update && apt-get install curl\n",
    "    curl --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35-36.Assignment: DNS Robin Test\n",
    "\n",
    "DNS Round Robin is the concept of two hosts with DNS aliases that respond to the  \n",
    "same DNS name.\n",
    "\n",
    "[Wikipedia Round-robin DNS](https://en.wikipedia.org/wiki/Round-robin_DNS): \n",
    "\n",
    "In its simplest implementation, round-robin DNS works by responding to DNS requests  \n",
    "not only with a single potential IP address, but with a list of potential IP addresses   \n",
    "corresponding to several servers that host identical services.The order in   \n",
    "which IP addresses from the list are returned is the basis for the term round robin.   \n",
    "\n",
    "Since Docker Engine 1.11, we can have multiple containers on a network respond to  \n",
    "the ssame DNS address.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment steps:\n",
    "\n",
    "1. create a vitual network\n",
    "2. create two containers from the elasticsearch:2 image\n",
    "    * research and use `--network-alias search` when creating the containers to  \n",
    "    give them an addtional DNS name to responde to\n",
    "3. run alpine `nslookup search` with `--net` to see the two containers list for   \n",
    "the same DNS name\n",
    "4. run centos `curl -s search:9200` with `--net` multiple times untill you see both  \n",
    "name fields show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "##create network \n",
    "docker network create my_app_net\n",
    "\n",
    "##create two elasctisearch containers \n",
    "docker container run -d --name elasticsearch_1 --network my_app_net --network-alias search elasticsearch:2\n",
    "docker container run -d --name elasticsearch_2 --network my_app_net --network-alias search elasticsearch:2\n",
    "\n",
    "##create alpine and centos containers\n",
    "docker run -d -t --name alpine_1 --network my_app_net alpine\n",
    "docker run -dt --name centos_1 --network my_app_net centos:7\n",
    "\n",
    "##nslookup from within the alpine container\n",
    "docker exec alpine_1 nslookup search\n",
    "\n",
    "##curl from within the centos container\n",
    "docker exec centos_1 curl -s search:9200\n",
    "\n",
    "##cleanup \n",
    "docker container rm -f alpine_1\n",
    "docker container rm -f centos_1\n",
    "docker container rm -f elasticsearch_1\n",
    "docker container rm -f elasticsearch_2\n",
    "docker network rm my_app_net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Container images, where to find them and how to build them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 37.What's In An Image (And What Isn't)\n",
    "\n",
    "What is an image:\n",
    "* An application's binaries and dependencies\n",
    "* The metadata about the image and how to run it\n",
    "\n",
    "**Official Definition**:  \n",
    "\"An image is an ordered collection of root filesystem changes and the   \n",
    "corresponding execution parameters for use within a container runtime.\"\n",
    "\n",
    "It is not a complete OS, it has no kernel/drivers etc. The host provides the  \n",
    "kernel. This is one of the main differences with virtual machines, a container  \n",
    "doesn't boot up a full operating system,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38.The Mighty Hub: Using Docker Hub Registry Images\n",
    "\n",
    "The official registry is found here: [Docker Hub](https://hub.docker.com/)\n",
    "\n",
    "Each application can have multiple images on the registry (e.g: nginx has   \n",
    "~90,000 images). To begin with, an easy choice is to start with the official   \n",
    "images that are curated by the team at Docker (who usualy work hand in hand   \n",
    "with the team that created the software).\n",
    "\n",
    "You can find documentation on how to run the image within its page on the hub.\n",
    "\n",
    "There are multiple versions of most official images. Each version can have more   \n",
    "than one tag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 39.Images & Their Layers: Discover The Image Cache\n",
    "\n",
    "Images don't just come as a single piece of data. They're usualy stacks of code   \n",
    "that build on top of each other (much like commits).\n",
    "\n",
    "They are designed using the union file concept of making layers of changes.\n",
    "\n",
    "The below is a history of the image layers. Every image start with a blank base   \n",
    "layer called \"scratch\", every change since then on the image file system is an   \n",
    "added layer. Every new layer has its own unique hash code (sha265).\n",
    "\n",
    "Images being stacks of layers can \"share\" cached layers that are common across   \n",
    "images (e.g: Two images can use the same scratch layer of Debian Jessie)\n",
    "\n",
    "In deploying containers, if you modify one of the files in the base layer that is   \n",
    "shared among containers. Only the difference is copied out. This is known as copy   \n",
    "on write, the differencing elements in the layers are copied into the container   \n",
    "that does the changes (not affecting the other containers). This means that the  \n",
    "containers can write files that will go on disk but the base image is read only  \n",
    "and will not be affected by what the containers do.\n",
    "\n",
    "The docker inspect command return metadata on the image in JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## inspect the nginx history\n",
    "docker image history nginx:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## get the metadata on the image\n",
    "docker image inspect nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40.Image Tagging & Publishing to Docker Hub\n",
    "\n",
    "Images don't have names, they have `IMAGE IDs`, `TAGs`.\n",
    "\n",
    "The syntax for image tags is: \\<user>/\\<repo>:\\<tag>\n",
    "\n",
    "A tag is a pointer to a specific image commit.\n",
    "\n",
    "You can have multiple tag to a single image ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## you can retag existing docker images\n",
    "docker image tag nginx karimitn/nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## push your image into you own repo in the registry\n",
    "docker image push karimitn/nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41.Building Images: The Dockerfile Basics\n",
    "\n",
    "The Dockerfile is like a recipe for creating containers.\n",
    "\n",
    "You will find code arranged into sections called `Stanzas` . The Script will look  \n",
    "like a bash script but technically it is not (it's a language unique to Docker).  \n",
    "\n",
    "To run it you use the command `docker run -f <some-docker-file>`\n",
    "\n",
    "The first stanza is the `FROM` command, its mandatory and is usually a minimal  \n",
    "linux distribution.\n",
    "\n",
    "Next is the`ENV` stanza, they are the main way of setting keys and values to run  \n",
    "containers.\n",
    "\n",
    "NOTE: Each stanza is an individual layer of the docker image. So the order in which  \n",
    "they are setup is critical as they work top-down.\n",
    "\n",
    "`RUN` is used to run CLI commands in the container as its being built. The &&  \n",
    "in the stanza is used to bundle the commands together and make them into a single  \n",
    "layer.\n",
    "\n",
    "`EXPOSE`, by default no TCP or UDP port are open inside a container. They don't  \n",
    "expose anything to the virtual network unless they are listed in this stanza.  \n",
    "This however doesn't mean these ports are open automatically on our host, that's  \n",
    "what the `-p` flag is used for.\n",
    "\n",
    "`CMD` is arequired stanza that will be run everytime a new container is run from  \n",
    "from the image or restart a container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat ./course_ressources/udemy-docker-mastery/dockerfile-sample-1/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42.Building Images: Running Docker Builds\n",
    "\n",
    "So what do we do with a Dockerfile? It's barelt 3Mb in size so how will we be able to  \n",
    "use it for anything? \n",
    "\n",
    "The `FROM` stanza will pull the linux distro from docker hub into my local cache.  \n",
    "It will then execute each of those stanzas inside my docker engine and then cache  \n",
    "them as layers. Each layer once built has a cache that gets stored this way the next  \n",
    "time you want to build this image (or another image that uses the same layer)  \n",
    "we can do it much quicker.\n",
    "\n",
    "If you change any line in a stanza then that line will be rerun (not usuing the cached layer).  \n",
    "Every stanza following that will also be rerun not from the cache.\n",
    "\n",
    "For example if you changed the EXPOSE stanza (e.g: added port 8080) then the CMD  \n",
    "stanza will also be rerun not from cache on the next build. This means if you want  \n",
    "to keep your build times low then you should preferably put the layers that are least  \n",
    "likely to change in the future at the top of the stack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -ltra ./course_ressources/udemy-docker-mastery/dockerfile-sample-1/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker image build -t custom_nginx -f ./course_ressources/udemy-docker-mastery/dockerfile-sample-1/Dockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43.Building Images: Extending Official Images\n",
    "\n",
    "`WORKDIR` is used to change the working directory  \n",
    "`COPY` is used to copy files from your local machine or build servers into the  \n",
    "the containers.  \n",
    "`CMD` command is mandatory but in this Dockerfile it is missing. However in the  \n",
    "`FROM` command we're using nginx, which has its own cmd specified in it. We inherit  \n",
    "from the images from which we're \"froming\". This is used to chain images and create  \n",
    "dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "ls -ltra ./course_ressources/udemy-docker-mastery/dockerfile-sample-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat ./course_ressources/udemy-docker-mastery/dockerfile-sample-2/Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd ./course_ressources/udemy-docker-mastery/dockerfile-sample-2/\n",
    "docker image build -t nginx-with-html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# running the below and navigating to localhost:80 will display a page with this text:\n",
    "# You just successfully ran a container with a custom file copied into the image at build time!\n",
    "docker run -p 80:80 --rm --name nginx-with-html nginx-with-html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker rm -f nginx-with-html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44-45.Assignment Build Your Own Dockerfile and Run Containers From It\n",
    "\n",
    "You don't necessarily need to understand the app that you're trying to \"Dockerize\".  \n",
    "You may however need to search and match images with what you need to build.\n",
    "\n",
    "In this assignement you're going to take an existing Node.js app and Dockerize it.  \n",
    "You don't have to know much about Node.js to be able to Dockerize it.\n",
    "\n",
    "Instruction for assignment are in   \n",
    "./course_ressources/udemy-docker-mastery/dockerfile-assignment-1/Dockerfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment Dockerfile :  \n",
    "\n",
    "FROM node:6-alpine\n",
    "\n",
    "EXPOSE 3000\n",
    "\n",
    "RUN apk add --update tini\n",
    "\n",
    "WORKDIR /usr/src/app\n",
    "\n",
    "COPY package.json package.json\n",
    "\n",
    "RUN npm install && npm cache clean --force\n",
    "\n",
    "COPY . .\n",
    "\n",
    "CMD [ \"/sbin/tini\", \"--\", \"node\", \"./bin/www\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#after modifying the Dockerfile\n",
    "cd ./course_ressources/udemy-docker-mastery/dockerfile-assignment-1/\n",
    "docker build -t testnode ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker run --name testnode_1 -p 80:3000 testnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker rm -f testnode_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# tag and push image to your registry\n",
    "docker tag testnode karimitn/testnode\n",
    "\n",
    "docker push karimitn/testnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker image rm karimitn/testnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "#docker image rm nginx-with-html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46.Usign Prune to Keep You Docker System Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker system df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker image prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker system prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6 : Container Lifetime and  Persistent Data: Volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47.Container lifetime and persistent data\n",
    "\n",
    "Containers are designed to be imutable and ephemarale, so how do you persist data?  \n",
    "This bring us to the concept of `separation of concerns`, the container should only   \n",
    "contain the applications binaries and not the data that it generates.  \n",
    "\n",
    "Docker has two solutions:\n",
    "\n",
    "1. Data volumes: make special location outside of containers' UFS (Union File System)\n",
    "2. Bind mounts: link container path to host path\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48.Persistent Data: Data Volumes\n",
    "\n",
    "Let's checkout the [mysql image](https://hub.docker.com/_/mysql).  \n",
    "\n",
    "In the Dockerfile you will see a `VOLUME` command:  VOLUME /var/lib/mysql  \n",
    "\n",
    "This command tell the container that any file that we put in there will outlive  \n",
    "the containers untill we delete the volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker pull mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker image inspect mysql -f {{.ContainerConfig.Volumes}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker run --name mysql -d -e MYSQL_ALOW_EMPTY_PASSWORD=True mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# we can see that the running container is gettig its own unique location to store  \n",
    "# data on the host. It thinks its writing to /var/lib/mysql but in actaullity it's \n",
    "# writing to the hosts /var/lib/docker/volumes/b62... directory\n",
    "docker container inspect mysql -f {{.Mounts}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker volume ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# in a linux machine you can just navigate to that mountpoint and see the data\n",
    "# however on Mac or Windows you can't because under teh hood the docker engine \n",
    "# is starting a linux VM in which the data lives\n",
    "docker volume inspect b62458d4f569966acd39a8db334d505198ae766869ea948eb568e13600ebe4cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named volumes\n",
    "\n",
    "The problem with volums is that from the `docker volume inspect` commnad you can't  \n",
    "see which containers are connected to the volume but from teh `docker container inspect`  \n",
    "you actually can.\n",
    "\n",
    "During the startup of a new container you can specify named containers to which   \n",
    "the containers will write. This is achieved using `-v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker run --name mysql2 -d -e MYSQL_ALOW_EMPTY_PASSWORD=True  -v mysql-db:/var/lib/mysql mysql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker volume inspect mysql-db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48-49.Persisting Data: Bind Mounts\n",
    "\n",
    "A mapping of host file/directory into a container file/directory. They are not  \n",
    "specified in the Dockerfiles because they ar host specific.  \n",
    "\n",
    "`... run -v /User/Karim/stuff:/path/container`\n",
    "\n",
    "Docker knows that its a bind mount and not a volume because mounts are start with  \n",
    "a forward slash.\n",
    "\n",
    "What differenciates them from volumes is that when you change files from the host  \n",
    "these changes cann be seen in realtime inside the container which is usefull for  \n",
    "development purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./course_ressources/udemy-docker-mastery/dockerfile-sample-2\n",
    "docker run -d -p 80:80 --name nginx -v $(pwd):/usr/share/nginx/html nginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "docker run -d -p 8080:80 --name nginx2 nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding how mount points work\n",
    "\n",
    "If you go to localhost:80 you will see that the html being displayed is not the  \n",
    "default from nginx but the one from the directory that is being mapped to the  \n",
    "container. However if you go to localhost:8080 which was started without the mount  \n",
    "the you will see the default index.html being displayed. That is because if two files  \n",
    "(from host and from container) have the same name, the one from the host \"wins\" and  \n",
    "is the one used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 51-52. Assignment: Database Upgrades with Named Volumes\n",
    "\n",
    "Updating the patch version of a postgres database. Outside of a container you  \n",
    "would upgrade the software however in containers you would not update what's  \n",
    "in a container but rather spin up a new container. So how should you proceed?  \n",
    "\n",
    "### Assignemnt Steps:\n",
    "\n",
    "1. Create a postgres container witha named volume psql-data using versio 9.6.1  \n",
    "2. Use docker hub to learn the volume path and the version needed to run it.  \n",
    "3. Check the logs on the startup of the firt container (admin user, default db)  \n",
    "and stop it.  \n",
    "4. Create a new postgress container with the same named volume using the newer  \n",
    "versio 9.6.2 (make sure the first container is stopped as you can't have two   \n",
    "containers using the same db)\n",
    "5. Check the logs and validate (you will see fewer startup log lines as the new  \n",
    "container doesn't have to repeat the same tasks that the first container has already  \n",
    "done)\n",
    "\n",
    "NOTE: this only works wit patch versions, most SQL DBs require manual commands   \n",
    "to upgrade DB to major/minor versions (its a DB limitation, not a container one).  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#check on existing volumes, you wont yet see psql-data volume\n",
    "docker volume ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run a postgres container of version 9.6.1-alpine.\n",
    "# Giving it a volume name that doesn't yet exist will get docker to create it\n",
    "# From the documentation you can see that the directory is used for access to volumes --> VOLUME [/var/lib/postgresql/data]\n",
    "# Link to image layers: https://hub.docker.com/layers/postgres/library/postgres/9.6.1-alpine/images/sha256-a47bdf2113e9a02e55899a26adebe3f5c64a3bd5c6e7e8abec39f18237607cf8?context=explore\n",
    "docker run -d -p 80:5432 --name postgres_9.6.1 -v psql-data:/var/lib/postgresql/data postgres:9.6.1-alpine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check the that volume was created\n",
    "docker volume inspect psql-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#inspec the image of postgres to see where it's configured for volumes\n",
    "docker image inspect postgres:9.6.1-alpine -f {{.ContainerConfig.Volumes}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#inspect the container to see to which volume it is mounted\n",
    "docker container inspect postgres_9.6.1 -f {{.Mounts}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# check the logs of the first container\n",
    "docker container logs postgres_9.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#stop the old container\n",
    "docker container stop postgres_9.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker run -d -p 80:5432 --name postgres_9.6.2 -v psql-data:/var/lib/postgresql/data postgres:9.6.2-alpine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# You will see a lot less log lines because the database is already created, you're  \n",
    "# Just starting a new container on a later patch version to use that database where it is\n",
    "docker container logs postgres_9.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cleanup\n",
    "docker container stop postgres_9.6.2\n",
    "docker container rm -f postgres_9.6.1 postgres_9.6.2\n",
    "docker volume rm psql-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53.File Permissions Across Multiple Containers\n",
    "\n",
    "At some point you'll have file permission problems, maybe you want multiple   \n",
    "containers to access the same volume(s), or maybe you're bind mounting existing  \n",
    "files into a container.  \n",
    "\n",
    "NOTE: This is for pure LINUX hosts, if using Docker Desktop locally it will do   \n",
    "the translation of host permissions (macOS, Windows) into the containers (Linux).  \n",
    "\n",
    "\n",
    "File ownership between the host and container are just numbers (sometime you will  \n",
    "see the user friendly names but there is a one-to-one aliasing between those in  \n",
    "`/etc/passwd & /etc/group`). The host will have those files and your container will  \n",
    "also have its own set of these files. The linux kernel only care about these IDs.  \n",
    "\n",
    "Two separate problems can occur: \n",
    "\n",
    "1. The `/etc/passwd` is different across containers:  \n",
    "Creating a named user in one container and running it as user ID 700 but in another  \n",
    "container it has another user ID means the two containers have different `/etc/passwd`  \n",
    "files. Different names are fine as long as the IDs math, two processes trying to  \n",
    "access the same file must have a matching userID or groupID.\n",
    "\n",
    "2. Two containers are running as different users:  \n",
    "Maybe the user/group IDs and/or the USER statement in your Dockerfiles are   \n",
    "different, and the two containers are technically running under different IDs.  \n",
    "To troubleshoot this you:  \n",
    "    *  Use `ps aux` in each container to see a list of the processes/usernames  \n",
    "    that are running. The process needs a matchin userID or groupID to access the  \n",
    "    files  \n",
    "    * Find the UID/GID in each container's `/etc/passwd` and `/etc/group` to  \n",
    "    translate names to numbers, you'll likely find a mismatch between the container  \n",
    "    that wrote the file and the container that is trying to read it.  \n",
    "    * Find a way to sync up the UID/GID, this is usualy easier to do in your own  \n",
    "    custom images than in the official 3rd party images. This may mean creating a new  \n",
    "    user in the one Dockerfile and the startup user with [USER](https://docs.docker.com/engine/reference/builder/#user)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54-55.Assignment: Edit Code Running In Containers With Bind Mounts\n",
    "\n",
    "You can edit files on host operating system and have them available in-sync inside  \n",
    "a running container. This is very cool for developement purposes as you can see changes  \n",
    "directly in the containers' behavior.\n",
    "\n",
    "### Assignment Steps:\n",
    "1. start a jekyll static website using the instructor's image in bretfisher/jekyll-serve\n",
    "2. make sure it is mounted to the working directory in which the assignment files   \n",
    "are present\n",
    "3. Update some of the files in the mounted directory and see them being reflected  \n",
    "in the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#start the container\n",
    "cd ./course_ressources/udemy-docker-mastery/bindmount-sample-1\n",
    "docker run -d -p 80:4000 -v $(pwd):/site --name jekyll-demo bretfisher/jekyll-serve \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# add some line to the markdown file that generates the static file\n",
    "# this change will be seem directly in the website as it hot reloads\n",
    "echo \"Here is some addtional line\" >> course_ressources/udemy-docker-mastery/bindmount-sample-1/_posts/2020-07-21-welcome-to-jekyll.markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# check the logs and see this in action \n",
    "docker container logs jekyll-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# cleanup\n",
    "docker container rm -f jekyll-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56.Database Passwords in Containers\n",
    "\n",
    "When running postgres now, you'll need to either set a password, or tell it to   \n",
    "allow any connection. \n",
    "\n",
    "Passwords need to be set during `docker run` using environment variables  \n",
    "`POSTGRES_PASSWORD=mypasswd` or tell ti to ignore passowrds `POSTGRES_HOST_AUTH_METHOD=trust`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Making It Easier with Docker Compose: The multi-container tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57.Docker Compose & The docker-compose.yml File\n",
    "\n",
    "Few software services are standalone, they would require other sevices to be running  \n",
    "(databases, front-end etc). How do  you make sure that the entire plant is up and running.\n",
    "\n",
    "There are two components:\n",
    "1. The docker-compose.yml file\n",
    "2. The docker-compose CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# A basic temaplate\n",
    "cat course_ressources/udemy-docker-mastery/compose-sample-1/template.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# The docker-compose.yml file for the jekyll website that we ran in a previous\n",
    "# assignment\n",
    "cat course_ressources/udemy-docker-mastery/compose-sample-1/docker-compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# The docker-compose.yml file for a sample wordpress setup\n",
    "cat course_ressources/udemy-docker-mastery/compose-sample-1/compose-2.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# The docker-compose.yml file for a 3 database cluster behind a ghost webserver\n",
    "cat course_ressources/udemy-docker-mastery/compose-sample-1/compose-3.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58.Trying Out Basic Compose Commands\n",
    "\n",
    "CLI tool come with Windows/Mac but on Linux you'll need to download it. It is not a   \n",
    "production-grade tool but its ideal for loca dev and test.\n",
    "\n",
    "Two of its most common commands are:\n",
    "1. docker compose up # setup volumes/networks & start all containers\n",
    "2. docker compose down #stop all containers and remove containers/volumes/networks\n",
    "\n",
    "If you had a Dockerfile and a docker-compose.yml, the \"new develloper onboarding\"  \n",
    "would look like this:\n",
    "* git clone github.com/some_path\n",
    "* docker compose up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd course_ressources/udemy-docker-mastery/compose-sample-2/\n",
    "ls -ltra .\n",
    "\n",
    "printf '\\n\\ndocker-compose.yml\\n---------------------\\n'\n",
    "cat docker-compose.yml\n",
    "\n",
    "printf '\\n\\nnginx.conf\\n---------------------\\n'\n",
    "cat nginx.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd course_ressources/udemy-docker-mastery/compose-sample-2/\n",
    "docker-compose up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd course_ressources/udemy-docker-mastery/compose-sample-2/\n",
    "docker-compose down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59.Version Dependenciess in Multi-Tier Apps\n",
    "It's important to remember that every app with dependencies, will also have  \n",
    "version requirements for those dependencies.\n",
    "\n",
    "If you add an app and a database to a Compose file, then that app is going to  \n",
    "have specific database versions it is compatible with.\n",
    "\n",
    "Version dependencies aren't new, so they aren't technically a Docker thing, but  \n",
    "we *do* use Docker and Compose to control versions of apps like Drupal, PostgreSQL,  \n",
    "MySQL, Redis, Wordpress, etc.\n",
    "\n",
    "Therefore, when building your Dockerfile and docker-compose.yml file, remember  \n",
    "that you'll need to check the compatible versions in that apps documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60-61-62.Assignment: Build a Compose File for a Multi-Container Project\n",
    "\n",
    "Steps:\n",
    "* Build a basic Drupal content management server. It will need a database behind it.  \n",
    "Use postgres\n",
    "* Use port to expose Drupal to 8080 so you can localhost:8080\n",
    "* Be sure to set POSTGRES_PASSWORD\n",
    "* Walk through Drupal setup via browser\n",
    "* Tip: Drupal assumes the database is in localhost. S the Drupal Container will  \n",
    "assume its within the container (for a container localhost is itself, the container).  \n",
    "That is in conflict with the principle of one container, one service (use the service name  \n",
    "instead for DNS resolution)\n",
    "* Extra credit: Use volumes to store Drupal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd course_ressources/udemy-docker-mastery/compose-assignment-1\n",
    "ls -trla\n",
    "mkdir assignment-submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer\n",
    "```\n",
    "version: '2'\n",
    "\n",
    "services:\n",
    "  drupal:\n",
    "    image: drupal:8.8.2\n",
    "    ports:\n",
    "      - \"8080:80\"\n",
    "    volumes:\n",
    "      - drupal-modules:/var/www/html/modules\n",
    "      - drupal-profiles:/var/www/html/profiles       \n",
    "      - drupal-sites:/var/www/html/sites      \n",
    "      - drupal-themes:/var/www/html/themes\n",
    "  postgres:\n",
    "    image: postgres:12.1\n",
    "    environment:\n",
    "      - POSTGRES_PASSWORD=mypasswd\n",
    "\n",
    "volumes:\n",
    "  drupal-modules:\n",
    "  drupal-profiles:\n",
    "  drupal-sites:\n",
    "  drupal-themes:\n",
    "\n",
    "        \n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd course_ressources/udemy-docker-mastery/compose-assignment-1/answer\n",
    "docker compose up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd course_ressources/udemy-docker-mastery/compose-assignment-1/answer\n",
    "docker compose down -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 63- Adding image building into compose files\n",
    "\n",
    "Docker compose will build images they're not found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd  ./course_ressources/udemy-docker-mastery/compose-sample-3\n",
    "ls -ltra\n",
    "\n",
    "# You can see that you specify dockerfile for the nginx image and you're linking\n",
    "# the html directory into the Apache container's directory\n",
    "cat docker-compose.yml\n",
    "\n",
    "cat nginx.Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 64-65.Assignment : Build and Run Compose\n",
    "\n",
    "Building a custom drupal image for local testing.\n",
    "\n",
    "Assignment directions:\n",
    "* Start with the compose file from the last assignment\n",
    "* Make you Dockerfile and docker-compose.yl in dir compose-assignemt-2\n",
    "* Use the README.md for details\n",
    "\n",
    "When you have a build and image key in the compose file you change the purpose of \n",
    "the image command. You're not pulling the image with that name form the registry  \n",
    "but are actually building from the directory specified inthe build/context field  \n",
    "and name that image with the name specified in the image field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission:\n",
    "\n",
    "\n",
    "```\n",
    "Dockerfile\n",
    "FROM drupal:8.2\n",
    "\n",
    "#RUN apt package manager command to install git\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y git \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "\n",
    "\n",
    "WORKDIR /var/www/html/themes\n",
    "\n",
    "#use git to clone the theme\n",
    "RUN git clone --branch 8.x-3.x --single-branch --depth 1 https://git.drupalcode.org/project/bootstrap.git \\\n",
    "    #we need to change permissions on files\n",
    "    && chown -R www-data:www-data bootstrap \n",
    "\n",
    "WORKDIR /var/www/html\n",
    "FROM drupal:8.2\n",
    "\n",
    "#RUN apt package manager command to install git\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y git \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "\n",
    "\n",
    "WORKDIR /var/www/html/themes\n",
    "\n",
    "#use git to clone the theme\n",
    "RUN git clone --branch 8.x-3.x --single-branch --depth 1 https://git.drupalcode.org/project/bootstrap.git \\\n",
    "    #we need to change permissions on files\n",
    "    && chown -R www-data:www-data bootstrap \n",
    "\n",
    "WORKDIR /var/www/html\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "docker-compose.yml\n",
    "version: '2'\n",
    "\n",
    "services:\n",
    "  drupal:\n",
    "    image: custom-drupal\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"8080:80\"\n",
    "    volumes:\n",
    "      - drupal-modules:/var/www/html/modules\n",
    "      - drupal-profiles:/var/www/html/profiles\n",
    "      - drupal-sites:/var/www/html/sites\n",
    "      - drupal-themes:/var/www/html/themes\n",
    "\n",
    "  postgres:\n",
    "    image: postgres:12.1\n",
    "    environment:\n",
    "      - POSTGRES_PASSWORD=mypasswd\n",
    "    volumes:\n",
    "      - drupal-data:/var/lib/postgresql/data\n",
    "volumes:\n",
    "  drupal-modules:\n",
    "  drupal-profiles:\n",
    "  drupal-sites:\n",
    "  drupal-themes:\n",
    "  drupal-data:\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd  ./course_ressources/udemy-docker-mastery/compose-assignment-2\n",
    "ls -ltra\n",
    "docker-compose up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: Swarm Intro and Creating a 3-node Swarm Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 66.Swarm Mode: Build-in Orchestration\n",
    "One of the big promises of containers is that we can easily deploy our apps  \n",
    "wether we're on-prem or with a cloud provider. However this poses new challenges  \n",
    "```\n",
    "How do we automate container lifecycle?  \n",
    "How can we easily scale out/in/up/down?\n",
    "How to ensure that containers are restarted if they fail?  \n",
    "How can we replace containers without downtime (blue/green deploy)?\n",
    "How to control/track where containers get started? \n",
    "How can we create cross-node virtual networks?  \n",
    "How can we ensure containers are running on only trusted servers?  \n",
    "How can we store secrets/keys/passowrds and get them to the right containers?  \n",
    "```  \n",
    "\n",
    "This is where `Swarm Mode` comes into play. Instead of Docker being just a container  \n",
    "runtime solution you get the added features of built-in orchestration. Its actually  \n",
    "a server clustering solution that brings together different operating systems or hosts  \n",
    "into a single manageable unit in which you can manage your container lifecycle in.  \n",
    "\n",
    "Added in 1.12 (summer 2016) via SwarmKit toolkit  \n",
    "Enhanced in 1.13 (Jan 2017) with Stacks and Secrets  \n",
    "It's not enabled by default, new commands once enable:  \n",
    "* docker swarm\n",
    "* docker node\n",
    "* docker service\n",
    "* docker stack\n",
    "* docker secret\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibit 1:\n",
    "\n",
    "* The blue boxes at the top are what we call manager nodes\n",
    "* They each have a database on them called the `RAFT` database\n",
    "    * It stores their configuration and all the information they need to be the  \n",
    "    authority inside a Swarm\n",
    "* In the exibit below you have three manager which each keep a copy of the RAFT  \n",
    "database. They encript their trafic in order to ensure the integrity and guarantee  \n",
    "the trust that they're able to manage the swarm securely.\n",
    "    * Below them you can see their `workers`\n",
    "* Each manager would be a virtual machine or a host and the exibit shows how they  \n",
    "communicate amond themselves over the `control plane`\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/images/section-7/exibit1.png\" width=\"800\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibit 2: \n",
    "* The Raft consensus database is replicated across al the nodes.  \n",
    "* The managers issue orders down to the workers.  \n",
    "* The Managers themselves can also be workers, they can be promoted/demoted into  \n",
    "the two roles.  \n",
    "* \n",
    "\n",
    "<div>\n",
    "<img src=\"assets/images/section-7/exibit2.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibit 3: \n",
    "* With the concept of Swarm we now have new concepts of what our containers look like.  \n",
    "* Because we needed new commands relating to scaling out, Swarm had additional commands. \n",
    "    * This is where the `docker service` comes into play. In a swarm it replaces  \n",
    "    the docker run command.\n",
    "    * It allows us to add new features to our containers such as `replicas`.\n",
    "* The manager/service would instanciate `tasks` \n",
    "    * a single service can have mutiple tasks, each one of them will launch a container.  \n",
    "* In the exibit below we tell our service that we require 3 nginx containers.\n",
    "    * The manager will decide where to placce them, by default it will try to spread them out.  \n",
    "    \n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/images/section-7/exibit3.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibit 4: \n",
    "* The exibit shows what the managers are doing in the background.\n",
    "    * The various APIs that help make decision on what the workers should be doing.  \n",
    "* The managers and workers are communicating, the workers report and request work from   \n",
    "the manager. The managers evaluate the state of the workers and decide on the orders to send down.  \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/images/section-7/exibit4.png\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 67.Create you first service and scale it out locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#to verify if swarm is on you can run the below\n",
    "docker info\n",
    "#you will see `Swarm: inactive` in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "## to enable the swarm features\n",
    "docker swarm init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens at initialisation of swarm\n",
    "* PKI & security automation    \n",
    "    * Root signing certificate create for our swarm\n",
    "    * Certificate is issues to the first manager node\n",
    "    * Join tokens are created\n",
    "    * [What is PKI? (Public Key Infrastructure)](https://www.keyfactor.com/resources/what-is-pki/)\n",
    "        * the most common form of encryption used today involves a public key,   \n",
    "        which anyone can use to encrypt a message, and a private key   \n",
    "        (also known as a secret key), which only one person should be able   \n",
    "        to use to decrypt those messages.\n",
    "        * Commonly used in [SSL Keys](https://www.keyfactor.com/blog/what-is-ssl-certificate/)\n",
    "* Creates teh radt database to store the root CA, configs, secrets\n",
    "    * RAFT is a protocole that ensures consistency across multiple nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## to see the node we just created \n",
    "docker node ls\n",
    "\n",
    "echo '------------------------------------------------------------------------'\n",
    "\n",
    "## to see the other options available on docker node\n",
    "docker node --help\n",
    "\n",
    "\n",
    "echo '------------------------------------------------------------------------'\n",
    "## to see options available on docker swarm \n",
    "docker swarm --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker service\n",
    "\n",
    "While `docker run` was focused on running containers on the current host, when we  \n",
    "think of clusters we send requirements at the swarm in the form of `services` and  \n",
    "they go ahead and do the heavy lifting of identifying which nodes/hosts to choose  \n",
    "and run the tasks/containers on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "## let's focus on the docker service command, it replaces docker run in swarm\n",
    "docker service --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# # to see the options on docker service create\n",
    "# docker service create --help\n",
    "# echo '------------------------------------------------------------------------'\n",
    "\n",
    "# #lets create a service \n",
    "docker service create alpine ping 8.8.8.8\n",
    "echo '------------------------------------------------------------------------'\n",
    "\n",
    "# #let see what got created \n",
    "docker service ls\n",
    "\n",
    "# #output would look like this:\n",
    "#ID             NAME              MODE         REPLICAS   IMAGE           PORTS\n",
    "#24rmqp3523th   exciting_dhawan   replicated   1/1        alpine:latest \n",
    "# 1- you get a service ID much like container IDs\n",
    "# 2- auto generated names\n",
    "# 3- a mode (replicated) as well as how many replicas were made\n",
    "echo '------------------------------------------------------------------------'\n",
    "\n",
    "# #let's see downstream of this, the cotainer that was created\n",
    "# #the name would be prepended with the name of the service that started that containers\n",
    "docker container ls \n",
    "\n",
    "#CONTAINER ID   IMAGE           COMMAND          CREATED         STATUS         PORTS     NAMES\n",
    "#c20f5d448259   alpine:latest   \"ping 8.8.8.8\"   4 minutes ago   Up 4 minutes             exciting_dhawan.1.zcs4g2t8fz2x1ex1b1ny4680m\n",
    "echo '------------------------------------------------------------------------'\n",
    "\n",
    "#let's see the process running within the container \n",
    "docker service ps exciting_dhawan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating/Scaling up a service\n",
    "Just like `docker container update` you have options that manage ressource usage.  \n",
    "However with service you have a lot more option because the goal is to manage multiple  \n",
    "tasks/containers and update them without downtime. In a scenario like that (blue/green update)  \n",
    "the containers will be updated and restarted in a pattern (one after the other) so that to  \n",
    "minimize downtime.\n",
    "\n",
    "In the below example you want to increase the number of replicas in that service.  \n",
    "docker service update <ID> --replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker service update 24rmqp3523th --replicas 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker service ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker service update --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When containers crash/get removed\n",
    "The service will compare the nuber of workers that are up with the specified  \n",
    "number of replicas. If there is a shortfall then it will start a new container to  \n",
    "replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE           COMMAND          CREATED          STATUS          PORTS     NAMES\n",
      "7d2bdbfa5a4d   alpine:latest   \"ping 8.8.8.8\"   55 seconds ago   Up 49 seconds             exciting_dhawan.1.nins7etlikycaqccldqwzhhk1\n",
      "2a72c128a704   alpine:latest   \"ping 8.8.8.8\"   11 minutes ago   Up 11 minutes             exciting_dhawan.3.udnibo4g3orzjy8jft2raliph\n",
      "cb83516446cc   alpine:latest   \"ping 8.8.8.8\"   11 minutes ago   Up 11 minutes             exciting_dhawan.2.i39ahhkfg7fpeet1jj7fllpfv\n",
      "ID             NAME              MODE         REPLICAS   IMAGE           PORTS\n",
      "24rmqp3523th   exciting_dhawan   replicated   3/3        alpine:latest   \n",
      "exciting_dhawan.1.nins7etlikycaqccldqwzhhk1\n",
      "CONTAINER ID   IMAGE           COMMAND          CREATED          STATUS          PORTS     NAMES\n",
      "a72f1c63a70b   alpine:latest   \"ping 8.8.8.8\"   10 seconds ago   Up 4 seconds              exciting_dhawan.1.ocps0dl9jlbaf2j04tf5oxipy\n",
      "2a72c128a704   alpine:latest   \"ping 8.8.8.8\"   12 minutes ago   Up 12 minutes             exciting_dhawan.3.udnibo4g3orzjy8jft2raliph\n",
      "cb83516446cc   alpine:latest   \"ping 8.8.8.8\"   12 minutes ago   Up 12 minutes             exciting_dhawan.2.i39ahhkfg7fpeet1jj7fllpfv\n",
      "ID             NAME              MODE         REPLICAS   IMAGE           PORTS\n",
      "24rmqp3523th   exciting_dhawan   replicated   3/3        alpine:latest   \n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker container ls\n",
    "docker service ls\n",
    "docker container rm -f exciting_dhawan.1.nins7etlikycaqccldqwzhhk1\n",
    "sleep 10\n",
    "docker container ls\n",
    "docker service ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70.Creating a 3-node swarm cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with docker\n",
    "\n",
    "In [Play with Docker](https://labs.play-with-docker.com/) create 3 instance. There a re other option,\n",
    "such as [Multipass](https://multipass.run/docs/mac-tutorial#heading--install-multipass) and [Digital Ocean](https://www.digitalocean.com/products/droplets)   \n",
    "however the first takes up memory/cpu on your local machine\n",
    "and the second is a paid service.\n",
    "\n",
    "\n",
    "Initialise docker swarm \n",
    "```\n",
    "$ docker swarm init \n",
    "Error response from daemon: could not choose an IP address to advertise since this system   \n",
    "has multiple addresses on different interfaces (172.18.0.9 on eth1 and 192.168.0.8 on eth0) - specify one with --advertise-add\n",
    "```\n",
    "\n",
    "\n",
    "The command will fail as it asks for an IP address to advertise/expose.\n",
    "\n",
    "```\n",
    "$ docker swarm init --advertise-addr 172.18.0.9\n",
    "Swarm initialized: current node (jik2jk58wxrqn5leqikv4z9a4) is now a manager.\n",
    "\n",
    "To add a worker to this swarm, run the following command:\n",
    "\n",
    "    docker swarm join --token SWMTKN-1-2z9is4g1wjzip6fg73jwwcbni9u1rwhrp6utbccd4bonrm357n-dpkea03mgidzefndkznk3vmm2 172.18.0.9:2377\n",
    "\n",
    "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n",
    "```\n",
    "\n",
    "\n",
    "Run the join command in the CLI of the remaining two machines:\n",
    "\n",
    "```\n",
    "docker swarm join --token SWMTKN-1-2z9is4g1wjzip6fg73jwwcbni9u1rwhrp6utbccd4bonrm357n-dpkea03mgidzefndkznk3vmm2 172.18.0.9:2377\n",
    "```\n",
    "\n",
    "\n",
    "Once all the nodes are added you can view a list of them\n",
    "```\n",
    "$ docker node ls\n",
    "ID                            HOSTNAME   STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION\n",
    "xalaxsijhtx31btfgqkyh9v0r *   node1      Ready     Active         Leader           20.10.17\n",
    "unmv51j0ann5rn69novt570jk     node2      Ready     Active                          20.10.17\n",
    "fkpahxqgoynr3vayd1bj38ttv     node3      Ready     Active                          20.10.17\n",
    "```\n",
    "\n",
    "\n",
    "If you try to run the same command from a worker node (2 or 3) you will get an error message\n",
    "```\n",
    "$ docker node ls\n",
    "Error response from daemon: This node is not a swarm manager. Worker nodes can't be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager.\n",
    "```\n",
    "\n",
    "\n",
    "You can promote a worker node to manager from one of the managers' CLI. \n",
    "```\n",
    "$ docker node update --role manager  node2\n",
    "node2\n",
    "```\n",
    "\n",
    "\n",
    "Now Node2 is able to run swarm commands. You see Node1 still the leader but Node2   \n",
    "is Reachable which means it's also a manager.\n",
    "```\n",
    "$ docker node ls\n",
    "ID                            HOSTNAME   STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION\n",
    "xalaxsijhtx31btfgqkyh9v0r *   node1      Ready     Active         Leader           20.10.17\n",
    "unmv51j0ann5rn69novt570jk     node2      Ready     Active         Reachable        20.10.17\n",
    "fkpahxqgoynr3vayd1bj38ttv     node3      Ready     Active                          20.10.17\n",
    "```\n",
    "\n",
    "Another option is to join a new node as a manger by default using a manager join token.   \n",
    "This can be obtained using the following command.  \n",
    "```\n",
    "$ docker swarm join-token manager\n",
    "To add a manager to this swarm, run the following command:\n",
    "\n",
    "    docker swarm join --token SWMTKN-1-31kn58ta7y5w54kjftr7vzd59wev14dvodqjqbtpq1gg37qsvw-147xrkg9dl9hibub9awtkc8f4 192.168.0.18:2377\n",
    "```\n",
    "\n",
    "\n",
    "Start a service, each of the replicas will run on one of the 3 nodes\n",
    "\n",
    "```\n",
    "$ docker service create --replicas 3 --name alpine-service  alpine ping 8.8.8.8\n",
    "```\n",
    "\n",
    "\n",
    "To checkout the running services\n",
    "```\n",
    "$ docker service ls\n",
    "ID             NAME             MODE         REPLICAS   IMAGE           PORTS\n",
    "czxar6jz3yhc   alpine-service   replicated   3/3        alpine:latest\n",
    "```\n",
    "\n",
    "\n",
    "To checkout the running processes for a service\n",
    "```\n",
    "$ docker service ps alpine-service \n",
    "ID             NAME               IMAGE           NODE      DESIRED STATE   CURRENT STATE                ERROR     PORTS\n",
    "mj7ej1b4dyem   alpine-service.1   alpine:latest   node1     Running         Running about a minute ago             \n",
    "v1zp1kw1eqd5   alpine-service.2   alpine:latest   node2     Running         Running about a minute ago             \n",
    "ktce87gsby2f   alpine-service.3   alpine:latest   node3     Running         Running about a minute ago \n",
    "```\n",
    "\n",
    "Teardown commands:\n",
    "```\n",
    "$ docker service rm alpine-service \n",
    "alpine-service\n",
    "\n",
    "$ docker swarm leave --force\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 9 : Swarm basic features and how to use them in your workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71 - Scaling out with Overlay Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay is networking driver, you choose it using the `--driver overlay` when creating   \n",
    "a new network. It creates a swarm-wide bridge network where the containers cross-host, on   \n",
    "the same network, can communicate as if they're on a a VLAN.   \n",
    "\n",
    "This is only for intra-swarm communication.   \n",
    "\n",
    "You can also enable [IPSec](https://en.wikipedia.org/wiki/IPsec) encryption but that is disbaled by default for performance   \n",
    "issues. This will setup IPSec tunnels between all the nodes of the swarm.\n",
    "\n",
    "When creating services they can be added to multiple overlay networks. (e.g: when you   \n",
    "have a front-end and a back, each on a separate network. Meantime you have an API   \n",
    "that communicates between back and front that is present on both networks).  \n",
    "\n",
    "### Demo:\n",
    "Deploy the drupal image from previous assignment and a postgres database as services  \n",
    "and create an overlay network for them to communicate.   \n",
    "\n",
    "\n",
    "#### Create a network \n",
    "```\n",
    "$ docker network create --driver overlay my-durpal\n",
    "hj2jrw181jxlrnre3bl65dzb \n",
    "\n",
    "$ docker network ls\n",
    "NETWORK ID     NAME              DRIVER    SCOPE\n",
    "6258415dbf03   bridge            bridge    local\n",
    "75784056bb8b   docker_gwbridge   bridge    local\n",
    "a6a6497adefa   host              host      local\n",
    "zitdye5xvyhd   ingress           overlay   swarm\n",
    "hj2jrw181jxl   my-durpal         overlay   swarm\n",
    "238cbd39dba8   none              null      local\n",
    "```\n",
    "\n",
    "\n",
    "#### Create a database service \n",
    "```\n",
    "$ docker service create --name psql --network my-drupal -e POSTGRES_PASSWORD=mypass postgres\n",
    "uno3rq7zqieczfvjpexufz8ji\n",
    "overall progress: 1 out of 1 tasks \n",
    "1/1: running   [==================================================>] \n",
    "verify: Service converged \n",
    "Karims-MacBook-Pro:Docker_Mastery karimitani$ \n",
    "\n",
    "```\n",
    "\n",
    "#### Inspect service\n",
    "```\n",
    "$ docker service ls \n",
    "ID             NAME      MODE         REPLICAS   IMAGE             PORTS\n",
    "uno3rq7zqiec   psql      replicated   1/1        postgres:latest\n",
    "\n",
    "$ docker service ps psql\n",
    "ID             NAME      IMAGE             NODE             DESIRED STATE   CURRENT STATE                ERROR     PORTS\n",
    "xc5vqwpgrcx2   psql.1    postgres:latest   docker-desktop   Running         Running about a minute ago \n",
    "\n",
    "$ docker service  logs psql \n",
    "psql.1.xc5vqwpgrcx2@docker-desktop    | The files belonging to this database system will be owned by user \"postgres\".\n",
    "psql.1.xc5vqwpgrcx2@docker-desktop    | This user must also own the server process.\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#### Create a drupal service\n",
    "```\n",
    "docker service create --name drupal --network my-durpal -p 80:80 drupal\n",
    "```\n",
    "\n",
    "#### Communication between the nodes\n",
    "When you navigate to the localhost:80 to setu drupal you will be asked for a database.  \n",
    "At that point the app will automatically discover the psql service because they are   \n",
    "both on the overlay network `my-durpal`.\n",
    "\n",
    "\n",
    "One thing to also notice is that even though your drupal service is running on one of the  \n",
    "three nodes, it responds to requests to any of the IP addresses of the three containers/processes  \n",
    "replicas in the services. That is because the routing mesh takes care of it,   \n",
    "more on that in the next lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72 - Scaling out with routing mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the routing mesh \n",
    "The routing mesh is an incoming (ingress) network for the service that distributes  \n",
    "packets to the tasks of the service. It spans all the nodes of a swarm and uses  \n",
    "[IVPS](https://en.wikipedia.org/wiki/IP_Virtual_Server) in linux kernel to do the distribution which implements transport-layer load balancing.\n",
    "\n",
    "Thee load balancing can be done in two way:\n",
    "\n",
    "**Container to Container in an overlay network using [VIP](https://en.wikipedia.org/wiki/IP_Virtual_Server).**   \n",
    "An example would be a database service with 2 or more replicas   \n",
    "where trafic from the front end service within the network talking to the   \n",
    "backend database service. Swarm would place a VIP in front of the services within the network.\n",
    "<div>\n",
    "<img src=\"assets/images/section9/exibit1.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "**External traffic incoming to published ports**\n",
    "\n",
    "The the routing mesh will place a VIP in front of all the services in the network   \n",
    "of the swarm and will load balance across them.\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/images/section9/exibit2.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "VIP is a statless balancer, you can setup nginx or HaProxy for statefull balancing.\n",
    "\n",
    "**HAProxy**\n",
    "\n",
    "<div>\n",
    "<img src=\"assets/images/section9/exibit3.png\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "#### Addtional documentation\n",
    "\n",
    "[Use swarm mode routing mesh](https://docs.docker.com/engine/swarm/ingress/)   \n",
    "[Use overlay networks](https://docs.docker.com/network/overlay/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73/74- Assignement: Create a multi node, multi service web app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Instructions (from course_ressources/udemy-docker-mastery/swarm-app-1)\n",
    "\n",
    "#### Goal: create networks, volumes, and services for a web-based \"cats vs. dogs\" voting app.\n",
    "Here is a basic diagram of how the 5 services will work:\n",
    "\n",
    "<div >\n",
    "    <img src=\"./course_ressources/udemy-docker-mastery/swarm-app-1/architecture.png\" style=\"max-width:400px ;\"/>\n",
    "</div>\n",
    "\n",
    "- All images are on Docker Hub, so you should use editor to craft your commands locally, then paste them into swarm shell (at least that's how I'd do it)\n",
    "- a `backend` and `frontend` overlay network are needed. Nothing different about them other than that backend will help protect database from the voting web app. (similar to how a VLAN setup might be in traditional architecture)\n",
    "- The database server should use a named volume for preserving data. Use the new `--mount` format to do this: `--mount type=volume,source=db-data,target=/var/lib/postgresql/data`\n",
    "\n",
    "#### Services (names below should be service names)\n",
    "- vote\n",
    "    - bretfisher/examplevotingapp_vote\n",
    "    - web front end for users to vote dog/cat\n",
    "    - ideally published on TCP 80. Container listens on 80\n",
    "    - on frontend network\n",
    "    - 2+ replicas of this container\n",
    "\n",
    "- redis\n",
    "    - redis:3.2\n",
    "    - key/value storage for incoming votes\n",
    "    - no public ports\n",
    "    - on frontend network\n",
    "    - 1 replica NOTE VIDEO SAYS TWO BUT ONLY ONE NEEDED\n",
    "\n",
    "- worker\n",
    "    - bretfisher/examplevotingapp_worker\n",
    "    - backend processor of redis and storing results in postgres\n",
    "    - no public ports\n",
    "    - on frontend and backend networks\n",
    "    - 1 replica\n",
    "\n",
    "- db\n",
    "    - postgres:9.4\n",
    "    - one named volume needed, pointing to /var/lib/postgresql/data\n",
    "    - on backend network\n",
    "    - 1 replica\n",
    "    - remember set env for password-less connections -e POSTGRES_HOST_AUTH_METHOD=trust\n",
    "\n",
    "- result\n",
    "    - bretfisher/examplevotingapp_result\n",
    "    - web app that shows results\n",
    "    - runs on high port since just for admins (lets imagine)\n",
    "    - so run on a high port of your choosing (I choose 5001), container listens on 80\n",
    "    - on backend network\n",
    "    - 1 replica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Submission\n",
    "\n",
    "#### Create overlay netwoks\n",
    "From a manager node run the below commands:\n",
    "\n",
    "docker network create --driver overlay backend \n",
    "docker network create --driver overlay frontend\n",
    "\n",
    "\n",
    "#### Pull the images from Docker hub \n",
    "\n",
    "docker pull bretfisher/examplevotingapp_vote\n",
    "docker pull redis:3.2\n",
    "docker pull bretfisher/examplevotingapp_worker\n",
    "docker pull postgres:9.4\n",
    "docker pull bretfisher/examplevotingapp_result\n",
    "\n",
    "\n",
    "#### Deploy images\n",
    "docker service create --name vote --replicas 2 --network frontend -p 80:80 bretfisher/examplevotingapp_vote\n",
    "docker service create --name redis --network frontend redis:3.2\n",
    "docker service create --name worker  --network frontend --network backend bretfisher/examplevotingapp_worker\n",
    "docker service create --name db  --network backend  -e POSTGRES_HOST_AUTH_METHOD=trust --mount type=volume,source=db-data,target=/var/lib/postgresql/data postgres:9.4\n",
    "docker service create --name result  -p 5001:80 --network backend bretfisher/examplevotingapp_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1a23c564728641ca86074dd852d1ffb282b3050b004cca28db58ced15900872"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
